#%Module -*- tcl -*-
##
## generated by ccspapp on 2019-07-18 13:45:20 +0100
## using cmd line:
##  "-d -c intel -o /home/ccspapp/temporary-intel-dirs/intel-modules.efhr6yr4KB/mpi/intel/2019/update4/intel -e PATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/bin -e MANPATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/man -e LD_LIBRARY_PATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/lib -e LIBRARY_PATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/lib -e CPATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/include -v GERUN_LAUNCHER=intel -e PATH:/shared/ucl/apps/intel-mpi/ucl-wrapper/bin -v MPI_HOME=/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243 -v I_MPI_ROOT=/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243 -v I_MPI_DEVICE=rdssm -v I_MPI_CC=icc -v I_MPI_CXX=icpc -v I_MPI_F90=ifort -v I_MPI_F77=ifort -v TMI_CONFIG=/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/etc/tmi.conf -e CMAKE_PREFIX_PATH:/shared/ucl/apps/intel/2019.Update4/impi/2019.4.243 -w [Intel MPI/2019.4.243] This is Intel's MPI implementation, version 2019.4.243, which is bundled with compiler package version 2019.Update4."

lappend auto_path /shared/ucl/apps/modulelibs/UsefulModuleFunctions
package require modulefunctions 1.0

proc ModulesHelp { } {

  puts stderr {[Intel MPI/2019.4.243] This is Intel's MPI implementation, version 2019.4.243, which is bundled with compiler package version 2019.Update4.}

}

module-whatis {[Intel MPI/2019.4.243] This is Intel's MPI implementation, version 2019.4.243, which is bundled with compiler package version 2019.Update4.}


conflict intel

set              prefix               /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243

# Add compatibility library for MPI built for infiniband not omnipath
if { [modulefunctions::isCluster grace] } {
    setenv FI_VERBS_IFACE ib0:1
}

setenv GERUN_LAUNCHER intel
setenv MPI_HOME /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243
setenv I_MPI_ROOT /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243
setenv INTEL_MPI_PATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243
#setenv I_MPI_DEVICE rdssm
setenv I_MPI_CC icc
setenv I_MPI_CXX icpc
setenv I_MPI_F90 ifort
setenv I_MPI_F77 ifort
#setenv TMI_CONFIG /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/etc/tmi.conf
prepend-path PATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/bin
prepend-path MANPATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/man
prepend-path LD_LIBRARY_PATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/lib
prepend-path LIBRARY_PATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/lib
prepend-path CPATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243/intel64/include
#prepend-path PATH /shared/ucl/apps/intel-mpi/ucl-wrapper/bin
prepend-path CMAKE_PREFIX_PATH /shared/ucl/apps/intel/2019.Update4/impi/2019.4.243

# use internal libfabric
prepend-path PATH               $prefix/intel64/libfabric/bin
prepend-path LD_LIBRARY_PATH    $prefix/intel64/libfabric/lib
prepend-path LIBRARY_PATH       $prefix/intel64/libfabric/lib
setenv FI_PROVIDER_PATH         $prefix/intel64/libfabric/lib/prov

# Check to see whether this is running in a scheduled environment (NHOSTS>1) and
# if not, set shared memory only.
if { [info exists ::env(NHOSTS) ] } {

        # Scheduled.
        # Check to see whether we have more than one host and if so set ofi and shared
        # memory, otherwise, set shared memory.
        if { $::env(NHOSTS) > 1} {

                # Multi-node, scheduled.
                setenv I_MPI_FABRICS shm:ofi
        } else {

                # Single node, scheduled.
                setenv I_MPI_FABRICS shm
        }
} else {

        # Not scheduled.
        setenv I_MPI_FABRICS shm
}

